#!/usr/bin/env python3import subprocessimport osimport argparseimport itertoolsfrom datetime import datetimedef parse_arguments():    parser = argparse.ArgumentParser(description='Run YOLOv8 Knowledge Distillation with multiple parameter combinations')        # Basic configuration (passed to knowledge_distillation.py)    parser.add_argument('--data', type=str, required=True, help='Path to data.yaml')    parser.add_argument('--student_model', type=str, default='yolov8n.yaml', help='Student model configuration')    parser.add_argument('--teacher_model', type=str, default='yolov8x.yaml', help='Teacher model configuration')    parser.add_argument('--teacher_weights', type=str, help='Path to pre-trained teacher weights')    parser.add_argument('--epochs', type=int, default=50, help='Number of training epochs')    parser.add_argument('--batch', type=int, default=16, help='Batch size')    parser.add_argument('--imgsz', type=int, default=640, help='Image size')    parser.add_argument('--device', type=str, default='0', help='Training device (GPU ID or cpu)')    parser.add_argument('--workers', type=int, default=4, help='Number of dataloader workers')    parser.add_argument('--skip_teacher', action='store_true', help='Skip teacher training (requires teacher_weights)')        # Hyperparameter grid search parameters    parser.add_argument('--alpha_values', type=float, nargs='+', default=[0.3, 0.5, 0.7, 0.9],                         help='List of alpha values to try')    parser.add_argument('--temperature_values', type=float, nargs='+', default=[1.0, 2.0, 3.0, 4.0],                         help='List of temperature values to try')    parser.add_argument('--output_dir', type=str, default='kd_experiments',                         help='Directory to store all experiment results')    parser.add_argument('--log_file', type=str, default='kd_grid_search.log',                        help='Log file to store all experiment outputs')        return parser.parse_args()def main():    args = parse_arguments()        # Create output directory    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")    experiment_dir = f"{args.output_dir}_{timestamp}"    os.makedirs(experiment_dir, exist_ok=True)        # Set up logging    log_path = os.path.join(experiment_dir, args.log_file)    log_file = open(log_path, 'w')    log_file.write(f"Starting Knowledge Distillation Grid Search at {timestamp}\n")    log_file.write("="*80 + "\n")    log_file.write(f"Base parameters:\n")        # Log base parameters    for key, value in vars(args).items():        if key not in ['alpha_values', 'temperature_values']:            log_file.write(f"  {key}: {value}\n")    log_file.write("="*80 + "\n\n")    log_file.flush()        # Generate combinations    combinations = list(itertools.product(args.alpha_values, args.temperature_values))    log_file.write(f"Running {len(combinations)} combinations of (alpha, temperature):\n")    for alpha, temp in combinations:        log_file.write(f"  ({alpha}, {temp})\n")    log_file.flush()        # Pre-train teacher once if not skipping    teacher_weights = args.teacher_weights    if not args.skip_teacher and not teacher_weights:        log_file.write("\nTraining teacher model first...\n")        log_file.flush()                # Construct command for teacher training        teacher_cmd = [            "python3", "knowledge_distillation.py",            "--data", args.data,            "--teacher_model", args.teacher_model,            "--student_model", args.student_model,            "--epochs", str(args.epochs),            "--batch", str(args.batch),            "--imgsz", str(args.imgsz),            "--device", args.device,            "--workers", str(args.workers),            "--teacher_name", f"teacher_{timestamp}"        ]                # Run teacher training        teacher_process = subprocess.Popen(            teacher_cmd,             stdout=subprocess.PIPE,             stderr=subprocess.STDOUT,            text=True        )                # Stream output to log file        for line in teacher_process.stdout:            log_file.write(line)            log_file.flush()                teacher_process.wait()                # Get teacher weights path        teacher_weights = f"runs/detect/teacher_{timestamp}/weights/best.pt"        if not os.path.exists(teacher_weights):            log_file.write(f"ERROR: Teacher weights not found at {teacher_weights}\n")            log_file.close()            return 1    # Run each combination    for i, (alpha, temperature) in enumerate(combinations):        experiment_name = f"kd_a{alpha}_t{temperature}_{timestamp}"        log_file.write("\n" + "="*80 + "\n")        log_file.write(f"Running experiment {i+1}/{len(combinations)}: alpha={alpha}, temperature={temperature}\n")        log_file.write("="*80 + "\n")        log_file.flush()                # Construct command        cmd = [            "python3", "knowledge_distillation.py",            "--data", args.data,            "--student_model", args.student_model,            "--teacher_model", args.teacher_model,            "--teacher_weights", teacher_weights,            "--epochs", str(args.epochs),            "--batch", str(args.batch),            "--imgsz", str(args.imgsz),            "--device", args.device,            "--workers", str(args.workers),            "--alpha", str(alpha),            "--temperature", str(temperature),            "--student_name", experiment_name         ]                # Add --skip_teacher flag if needed        if args.skip_teacher:            cmd.append("--skip_teacher")                # Run command        process = subprocess.Popen(            cmd,             stdout=subprocess.PIPE,             stderr=subprocess.STDOUT,            text=True        )                # Stream output to log file        for line in process.stdout:            log_file.write(line)            log_file.flush()                process.wait()                # Check if training was successful        results_path = f"runs/detect/{experiment_name}/results.csv"        if os.path.exists(results_path):            # Copy results to experiment directory            copy_cmd = f"cp {results_path} {experiment_dir}/{experiment_name}_results.csv"            subprocess.run(copy_cmd, shell=True)            log_file.write(f"Results saved to {experiment_dir}/{experiment_name}_results.csv\n")        else:            log_file.write(f"WARNING: Results file not found at {results_path}\n")    # Create summary of all runs    log_file.write("\n" + "="*80 + "\n")    log_file.write("Grid Search Summary\n")    log_file.write("="*80 + "\n")        # Try to extract final metrics from each run    summary_data = []    for alpha, temperature in combinations:        experiment_name = f"kd_a{alpha}_t{temperature}_{timestamp}"        results_path = f"{experiment_dir}/{experiment_name}_results.csv"                if os.path.exists(results_path):            # Get the last line from results.csv for final metrics            with open(results_path, 'r') as f:                lines = f.readlines()                if len(lines) > 1:  # Header + at least one data line                    last_line = lines[-1].strip()                    summary_data.append((alpha, temperature, last_line))    # Write summary    if summary_data:        # Write header (assuming all result files have same format)        with open(f"{experiment_dir}/{experiment_name}_results.csv", 'r') as f:            header = f.readline().strip()                log_file.write(f"alpha,temperature,{header}\n")                # Write data        for alpha, temperature, metrics in summary_data:            log_file.write(f"{alpha},{temperature},{metrics}\n")    log_file.write("\nExperiment completed. All results are saved in: " + experiment_dir + "\n")    log_file.close()        print(f"Grid search completed. All results and logs saved to: {experiment_dir}")    return 0if __name__ == '__main__':    exit_code = main()    exit(exit_code)
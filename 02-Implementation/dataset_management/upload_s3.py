import osimport zipfileimport boto3import argparsefrom version_manager import generate_new_version# Configuration with Jenkins secret supportAWS_ACCESS_KEY_ID = os.environ.get("AWS_ACCESS_KEY_ID")AWS_SECRET_ACCESS_KEY = os.environ.get("AWS_SECRET_ACCESS_KEY")AWS_DEFAULT_REGION = os.environ.get("AWS_DEFAULT_REGION", "us-east-1")S3_BUCKET_NAME = os.environ.get("S3_BUCKET_NAME", "yolov8-model-repository")S3_FOLDER_PATH = os.environ.get("S3_FOLDER_PATH", "yolov8_model_custom")DEFAULT_ZIP_NAME = os.environ.get("DEFAULT_ZIP_NAME", "archive.zip")DELETE_ZIP_AFTER_UPLOAD = os.environ.get("DELETE_ZIP_AFTER_UPLOAD", "true").lower() == "true"def zip_directory(directory_path: str, output_path: str):    """Compresses a directory into a zip file."""    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:        for root, dirs, files in os.walk(directory_path):            for file in files:                file_path = os.path.join(root, file)                arcname = os.path.relpath(file_path, directory_path)                zipf.write(file_path, arcname)def upload_to_s3(file_path: str, bucket_name: str, s3_key: str):    """Uploads a file to AWS S3 using credentials from Jenkins environment."""    if not AWS_ACCESS_KEY_ID or not AWS_SECRET_ACCESS_KEY:        print("[ERROR] AWS credentials not found in environment")        raise ValueError("AWS credentials missing - ensure they are configured in Jenkins")            s3 = boto3.client(        's3',        aws_access_key_id=AWS_ACCESS_KEY_ID,        aws_secret_access_key=AWS_SECRET_ACCESS_KEY,        region_name=AWS_DEFAULT_REGION    )    with open(file_path, 'rb') as file:        s3.upload_fileobj(file, bucket_name, s3_key)def main():    parser = argparse.ArgumentParser(description="Zip a folder and upload to AWS S3.")    parser.add_argument("source_folder", help="Path to the folder to zip and upload")    parser.add_argument("--project", help="Project name (defaults to folder name if not specified)")    parser.add_argument("s3_subfolder", nargs="?", default=S3_FOLDER_PATH,                        help="Optional subfolder in S3 bucket")    parser.add_argument("--notes", default="Automated upload", help="Notes for this version")    args = parser.parse_args()        if not args.source_folder or not S3_BUCKET_NAME:        print("[ERROR] SOURCE_FOLDER must be defined and S3_BUCKET_NAME is required")        return            dir_name = os.path.basename(args.source_folder.rstrip("/"))    project_name = args.project if args.project else dir_name    version = generate_new_version(project_name, notes=args.notes)    zip_name = f"{project_name}_{version}.zip"    zip_path = os.path.join("/tmp", zip_name)        print(f"[INFO] Zipping folder '{args.source_folder}' into '{zip_path}'...")    zip_directory(args.source_folder, zip_path)        s3_key = os.path.join(args.s3_subfolder, zip_name) if args.s3_subfolder else zip_name    print(f"[INFO] Uploading '{zip_path}' to 's3://{S3_BUCKET_NAME}/{s3_key}'...")    upload_to_s3(zip_path, S3_BUCKET_NAME, s3_key)    print("[✓] Upload completed!")        if DELETE_ZIP_AFTER_UPLOAD:        os.remove(zip_path)        print("[✓] Local zip deleted.")if __name__ == "__main__":    main()